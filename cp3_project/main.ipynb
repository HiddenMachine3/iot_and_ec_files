{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>H-050</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>RDCHI</th>\n",
       "      <th>GATS1p</th>\n",
       "      <th>nN</th>\n",
       "      <th>C-040</th>\n",
       "      <th>quantitative response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.419</td>\n",
       "      <td>1.225</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.638</td>\n",
       "      <td>1.401</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.799</td>\n",
       "      <td>2.930</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.453</td>\n",
       "      <td>2.887</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.068</td>\n",
       "      <td>2.758</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPSA(Tot)  SAacc  H-050  MLOGP  RDCHI  GATS1p  nN  C-040  \\\n",
       "0       0.00    0.0      0  2.419  1.225   0.667   0      0   \n",
       "1       0.00    0.0      0  2.638  1.401   0.632   0      0   \n",
       "2       9.23   11.0      0  5.799  2.930   0.486   0      0   \n",
       "3       9.23   11.0      0  5.453  2.887   0.495   0      0   \n",
       "4       9.23   11.0      0  4.068  2.758   0.695   0      0   \n",
       "\n",
       "   quantitative response  \n",
       "0                  3.740  \n",
       "1                  4.330  \n",
       "2                  7.019  \n",
       "3                  6.723  \n",
       "4                  5.979  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"TPSA(Tot)\", \"SAacc\", \"H-050\", \"MLOGP\", \"RDCHI\", \"GATS1p\", \"nN\", \"C-040\", \"quantitative response\"]\n",
    "df = pd.read_csv('qsar_aquatic_toxicity.csv', names=column_names, delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "x_train, y_train = train_df.drop('quantitative response', axis=1), train_df['quantitative response']\n",
    "x_test, y_test = test_df.drop('quantitative response', axis=1), test_df['quantitative response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>H-050</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>RDCHI</th>\n",
       "      <th>GATS1p</th>\n",
       "      <th>nN</th>\n",
       "      <th>C-040</th>\n",
       "      <th>quantitative response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>75.99</td>\n",
       "      <td>73.774</td>\n",
       "      <td>1</td>\n",
       "      <td>0.787</td>\n",
       "      <td>2.266</td>\n",
       "      <td>1.185</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>45.82</td>\n",
       "      <td>50.747</td>\n",
       "      <td>0</td>\n",
       "      <td>3.110</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.478</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>111.87</td>\n",
       "      <td>144.177</td>\n",
       "      <td>1</td>\n",
       "      <td>1.748</td>\n",
       "      <td>2.377</td>\n",
       "      <td>0.839</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>12.53</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.533</td>\n",
       "      <td>2.274</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>46.53</td>\n",
       "      <td>78.828</td>\n",
       "      <td>1</td>\n",
       "      <td>2.086</td>\n",
       "      <td>2.455</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TPSA(Tot)    SAacc  H-050  MLOGP  RDCHI  GATS1p  nN  C-040  \\\n",
       "147      75.99   73.774      1  0.787  2.266   1.185   2      0   \n",
       "251      45.82   50.747      0  3.110  2.165   0.478   1      0   \n",
       "400     111.87  144.177      1  1.748  2.377   0.839   2      0   \n",
       "319      12.53   11.000      0  1.533  2.274   1.026   0      0   \n",
       "353      46.53   78.828      1  2.086  2.455   0.941   0      1   \n",
       "\n",
       "     quantitative response  \n",
       "147                  5.551  \n",
       "251                  4.434  \n",
       "400                  4.790  \n",
       "319                  4.018  \n",
       "353                  3.047  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 128)               1152      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DENSE1_SIZE = 128\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(x_train.shape[1:])),\n",
    "  tf.keras.layers.Dense(DENSE1_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 8])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276.06793"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_test.to_numpy(), predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 1s 18ms/step - loss: 149.3089 - mse: 149.3089 - mae: 8.2881 - val_loss: 42.9603 - val_mse: 42.9603 - val_mae: 4.2211\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 100.0844 - mse: 100.0844 - mae: 5.7769 - val_loss: 14.1926 - val_mse: 14.1926 - val_mae: 2.9992\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 46.0757 - mse: 46.0757 - mae: 5.0537 - val_loss: 9.8920 - val_mse: 9.8920 - val_mae: 2.7765\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 50.9113 - mse: 50.9113 - mae: 4.7766 - val_loss: 6.3369 - val_mse: 6.3369 - val_mae: 1.9581\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 40.7901 - mse: 40.7901 - mae: 4.1394 - val_loss: 4.7490 - val_mse: 4.7490 - val_mae: 1.8429\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 30.2728 - mse: 30.2728 - mae: 3.6898 - val_loss: 3.8224 - val_mse: 3.8224 - val_mae: 1.4826\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 40.2209 - mse: 40.2209 - mae: 3.9149 - val_loss: 3.2473 - val_mse: 3.2473 - val_mae: 1.2994\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 47.1316 - mse: 47.1316 - mae: 3.6792 - val_loss: 3.1655 - val_mse: 3.1655 - val_mae: 1.4244\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 28.6004 - mse: 28.6004 - mae: 3.5574 - val_loss: 5.2288 - val_mse: 5.2288 - val_mae: 1.8516\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 32.3986 - mse: 32.3986 - mae: 3.4716 - val_loss: 3.9924 - val_mse: 3.9924 - val_mae: 1.2900\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 27.9179 - mse: 27.9179 - mae: 3.2281 - val_loss: 1.9707 - val_mse: 1.9707 - val_mae: 1.0611\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 30.4813 - mse: 30.4813 - mae: 3.3445 - val_loss: 6.6616 - val_mse: 6.6616 - val_mae: 2.0128\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 42.6161 - mse: 42.6161 - mae: 3.7769 - val_loss: 4.8887 - val_mse: 4.8887 - val_mae: 1.4580\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 23.6353 - mse: 23.6353 - mae: 3.1355 - val_loss: 1.6811 - val_mse: 1.6811 - val_mae: 0.9477\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 22.5417 - mse: 22.5417 - mae: 3.0744 - val_loss: 2.3094 - val_mse: 2.3094 - val_mae: 1.1466\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 25.3876 - mse: 25.3876 - mae: 3.1518 - val_loss: 2.8828 - val_mse: 2.8828 - val_mae: 1.1233\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 19.8332 - mse: 19.8332 - mae: 2.8891 - val_loss: 4.2829 - val_mse: 4.2829 - val_mae: 1.5852\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.5066 - mse: 19.5066 - mae: 2.9350 - val_loss: 1.5430 - val_mse: 1.5430 - val_mae: 0.9340\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 19.5980 - mse: 19.5980 - mae: 2.7581 - val_loss: 1.9442 - val_mse: 1.9442 - val_mae: 1.0334\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 15.7495 - mse: 15.7495 - mae: 2.6581 - val_loss: 2.4222 - val_mse: 2.4222 - val_mae: 1.1614\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 19.9526 - mse: 19.9526 - mae: 2.8186 - val_loss: 3.4007 - val_mse: 3.4007 - val_mae: 1.2507\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 19.2088 - mse: 19.2088 - mae: 2.7794 - val_loss: 5.0135 - val_mse: 5.0135 - val_mae: 1.6021\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 24.0974 - mse: 24.0974 - mae: 2.8421 - val_loss: 4.3673 - val_mse: 4.3673 - val_mae: 1.4035\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 17.7597 - mse: 17.7597 - mae: 2.7235 - val_loss: 1.6776 - val_mse: 1.6776 - val_mae: 0.9738\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 15.1553 - mse: 15.1553 - mae: 2.4897 - val_loss: 1.9915 - val_mse: 1.9915 - val_mae: 1.0516\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 23.7891 - mse: 23.7891 - mae: 2.6991 - val_loss: 1.5511 - val_mse: 1.5511 - val_mae: 0.9355\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 20.0617 - mse: 20.0617 - mae: 2.7487 - val_loss: 8.7992 - val_mse: 8.7992 - val_mae: 1.9230\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 18.2451 - mse: 18.2451 - mae: 2.6553 - val_loss: 4.2666 - val_mse: 4.2666 - val_mae: 1.5836\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 17.1395 - mse: 17.1395 - mae: 2.4968 - val_loss: 3.3220 - val_mse: 3.3220 - val_mae: 1.2434\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.8497 - mse: 13.8497 - mae: 2.3287 - val_loss: 2.2110 - val_mse: 2.2110 - val_mae: 1.1193\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 14.6973 - mse: 14.6973 - mae: 2.3451 - val_loss: 2.5035 - val_mse: 2.5035 - val_mae: 1.1980\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 14.0813 - mse: 14.0813 - mae: 2.3047 - val_loss: 1.4333 - val_mse: 1.4333 - val_mae: 0.9021\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 13.7486 - mse: 13.7486 - mae: 2.3039 - val_loss: 1.4402 - val_mse: 1.4402 - val_mae: 0.9159\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.7086 - mse: 12.7086 - mae: 2.1209 - val_loss: 1.9910 - val_mse: 1.9910 - val_mae: 1.0566\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.1131 - mse: 8.1131 - mae: 2.0045 - val_loss: 1.6358 - val_mse: 1.6358 - val_mae: 0.9826\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 16.2807 - mse: 16.2807 - mae: 2.2764 - val_loss: 3.5781 - val_mse: 3.5781 - val_mae: 1.4099\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 14.5849 - mse: 14.5849 - mae: 2.2873 - val_loss: 1.7437 - val_mse: 1.7437 - val_mae: 0.9722\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.6886 - mse: 9.6886 - mae: 2.0747 - val_loss: 1.3590 - val_mse: 1.3590 - val_mae: 0.8779\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.1283 - mse: 8.1283 - mae: 1.8915 - val_loss: 1.8615 - val_mse: 1.8615 - val_mae: 1.0045\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 8.5047 - mse: 8.5047 - mae: 1.9517 - val_loss: 1.6566 - val_mse: 1.6566 - val_mae: 0.9564\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 9.0468 - mse: 9.0468 - mae: 1.9191 - val_loss: 1.6867 - val_mse: 1.6867 - val_mae: 0.9473\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 9.8231 - mse: 9.8231 - mae: 1.9974 - val_loss: 1.4615 - val_mse: 1.4615 - val_mae: 0.9233\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 8.6796 - mse: 8.6796 - mae: 1.8939 - val_loss: 1.5804 - val_mse: 1.5804 - val_mae: 0.9466\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 12.0166 - mse: 12.0166 - mae: 2.0151 - val_loss: 1.3921 - val_mse: 1.3921 - val_mae: 0.8978\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 12.1061 - mse: 12.1061 - mae: 1.9229 - val_loss: 1.6477 - val_mse: 1.6477 - val_mae: 0.9513\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 7.0516 - mse: 7.0516 - mae: 1.7451 - val_loss: 2.0219 - val_mse: 2.0219 - val_mae: 1.0401\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 8.4893 - mse: 8.4893 - mae: 1.9567 - val_loss: 1.5972 - val_mse: 1.5972 - val_mae: 0.9806\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 6.1413 - mse: 6.1413 - mae: 1.7011 - val_loss: 1.6383 - val_mse: 1.6383 - val_mae: 0.9556\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 11.6570 - mse: 11.6570 - mae: 1.8500 - val_loss: 2.7614 - val_mse: 2.7614 - val_mae: 1.1730\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 7.3509 - mse: 7.3509 - mae: 1.7797 - val_loss: 1.8850 - val_mse: 1.8850 - val_mae: 1.0213\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 5.5243 - mse: 5.5243 - mae: 1.6371 - val_loss: 1.8271 - val_mse: 1.8271 - val_mae: 1.0028\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 6.0616 - mse: 6.0616 - mae: 1.7019 - val_loss: 1.5942 - val_mse: 1.5942 - val_mae: 0.9319\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.9830 - mse: 5.9830 - mae: 1.6728 - val_loss: 1.3022 - val_mse: 1.3022 - val_mae: 0.8500\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.5707 - mse: 5.5707 - mae: 1.6492 - val_loss: 1.5542 - val_mse: 1.5542 - val_mae: 0.9320\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 7.1800 - mse: 7.1800 - mae: 1.7601 - val_loss: 1.3317 - val_mse: 1.3317 - val_mae: 0.8627\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 8.2274 - mse: 8.2274 - mae: 1.7688 - val_loss: 2.1991 - val_mse: 2.1991 - val_mae: 1.0575\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.6771 - mse: 5.6771 - mae: 1.7084 - val_loss: 1.9188 - val_mse: 1.9188 - val_mae: 1.0215\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.4646 - mse: 5.4646 - mae: 1.6010 - val_loss: 1.3387 - val_mse: 1.3387 - val_mae: 0.8752\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.2970 - mse: 5.2970 - mae: 1.6504 - val_loss: 1.4604 - val_mse: 1.4604 - val_mae: 0.8961\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4.3566 - mse: 4.3566 - mae: 1.5080 - val_loss: 1.3466 - val_mse: 1.3466 - val_mae: 0.8807\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.2559 - mse: 7.2559 - mae: 1.6594 - val_loss: 1.4215 - val_mse: 1.4215 - val_mae: 0.9004\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 7.8453 - mse: 7.8453 - mae: 1.8830 - val_loss: 3.4522 - val_mse: 3.4522 - val_mae: 1.3599\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 6.6106 - mse: 6.6106 - mae: 1.6511 - val_loss: 2.4259 - val_mse: 2.4259 - val_mae: 1.1129\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.1838 - mse: 5.1838 - mae: 1.5707 - val_loss: 1.4573 - val_mse: 1.4573 - val_mae: 0.9042\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4.3656 - mse: 4.3656 - mae: 1.5140 - val_loss: 1.5179 - val_mse: 1.5179 - val_mae: 0.9313\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 5.4329 - mse: 5.4329 - mae: 1.5298 - val_loss: 1.3719 - val_mse: 1.3719 - val_mae: 0.8999\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4.7053 - mse: 4.7053 - mae: 1.4580 - val_loss: 1.3554 - val_mse: 1.3554 - val_mae: 0.8971\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4.7164 - mse: 4.7164 - mae: 1.5268 - val_loss: 1.3505 - val_mse: 1.3505 - val_mae: 0.8890\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.6821 - mse: 7.6821 - mae: 1.6180 - val_loss: 1.3564 - val_mse: 1.3564 - val_mae: 0.8867\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 4.4635 - mse: 4.4635 - mae: 1.4791 - val_loss: 1.4005 - val_mse: 1.4005 - val_mae: 0.8755\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.7779 - mse: 3.7779 - mae: 1.4132 - val_loss: 1.3591 - val_mse: 1.3591 - val_mae: 0.8695\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 4.7419 - mse: 4.7419 - mae: 1.4195 - val_loss: 1.4567 - val_mse: 1.4567 - val_mae: 0.9151\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 5.4105 - mse: 5.4105 - mae: 1.4943 - val_loss: 1.3446 - val_mse: 1.3446 - val_mae: 0.8925\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4.1549 - mse: 4.1549 - mae: 1.4360 - val_loss: 1.3377 - val_mse: 1.3377 - val_mae: 0.8842\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.8411 - mse: 3.8411 - mae: 1.3886 - val_loss: 1.4036 - val_mse: 1.4036 - val_mae: 0.8763\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 3.7665 - mse: 3.7665 - mae: 1.3969 - val_loss: 1.5957 - val_mse: 1.5957 - val_mae: 0.9394\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3.4409 - mse: 3.4409 - mae: 1.2971 - val_loss: 1.3177 - val_mse: 1.3177 - val_mae: 0.8644\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2099 - mse: 3.2099 - mae: 1.2995 - val_loss: 1.2924 - val_mse: 1.2924 - val_mae: 0.8731\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2657 - mse: 3.2657 - mae: 1.3029 - val_loss: 1.3220 - val_mse: 1.3220 - val_mae: 0.8913\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.3374 - mse: 3.3374 - mae: 1.3199 - val_loss: 1.3385 - val_mse: 1.3385 - val_mae: 0.8862\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.2018 - mse: 3.2018 - mae: 1.2775 - val_loss: 1.3409 - val_mse: 1.3409 - val_mae: 0.8812\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.9036 - mse: 3.9036 - mae: 1.4045 - val_loss: 1.3427 - val_mse: 1.3427 - val_mae: 0.8708\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3.6921 - mse: 3.6921 - mae: 1.3831 - val_loss: 1.7270 - val_mse: 1.7270 - val_mae: 0.9959\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4.2630 - mse: 4.2630 - mae: 1.4026 - val_loss: 1.6391 - val_mse: 1.6391 - val_mae: 0.9518\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.9001 - mse: 3.9001 - mae: 1.3482 - val_loss: 1.3235 - val_mse: 1.3235 - val_mae: 0.8775\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.2674 - mse: 3.2674 - mae: 1.2973 - val_loss: 1.3375 - val_mse: 1.3375 - val_mae: 0.8914\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 4.2428 - mse: 4.2428 - mae: 1.3975 - val_loss: 1.2936 - val_mse: 1.2936 - val_mae: 0.8852\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3.1460 - mse: 3.1460 - mae: 1.3180 - val_loss: 1.3176 - val_mse: 1.3176 - val_mae: 0.8835\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.9611 - mse: 2.9611 - mae: 1.2555 - val_loss: 1.2912 - val_mse: 1.2912 - val_mae: 0.8859\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2575 - mse: 3.2575 - mae: 1.2838 - val_loss: 1.3697 - val_mse: 1.3697 - val_mae: 0.8757\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.0782 - mse: 3.0782 - mae: 1.2356 - val_loss: 1.3309 - val_mse: 1.3309 - val_mae: 0.8881\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.0076 - mse: 3.0076 - mae: 1.2706 - val_loss: 1.4708 - val_mse: 1.4708 - val_mae: 0.8910\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.2321 - mse: 3.2321 - mae: 1.2662 - val_loss: 1.3614 - val_mse: 1.3614 - val_mae: 0.8972\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 3.0579 - mse: 3.0579 - mae: 1.2428 - val_loss: 1.3990 - val_mse: 1.3990 - val_mae: 0.8860\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.8984 - mse: 2.8984 - mae: 1.2298 - val_loss: 1.2766 - val_mse: 1.2766 - val_mae: 0.8841\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 3.0690 - mse: 3.0690 - mae: 1.2417 - val_loss: 1.3140 - val_mse: 1.3140 - val_mae: 0.8903\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.5631 - mse: 2.5631 - mae: 1.1877 - val_loss: 1.3047 - val_mse: 1.3047 - val_mae: 0.8967\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 2.7505 - mse: 2.7505 - mae: 1.2035 - val_loss: 1.3224 - val_mse: 1.3224 - val_mae: 0.8980\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 3.0690 - mse: 3.0690 - mae: 1.2386 - val_loss: 1.3456 - val_mse: 1.3456 - val_mae: 0.8910\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 2.6285 - mse: 2.6285 - mae: 1.1787 - val_loss: 1.3005 - val_mse: 1.3005 - val_mae: 0.8784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d52b195b48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OF_EPOCHS = 100\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test), epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 1.3005 - mse: 1.3005 - mae: 0.8784 - 37ms/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3004882335662842, 1.3004882335662842, 0.8784268498420715]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.794524 ],\n",
       "       [4.2097225],\n",
       "       [5.700759 ],\n",
       "       [3.1478136],\n",
       "       [2.2720077],\n",
       "       [2.6499338],\n",
       "       [4.558362 ],\n",
       "       [5.2574883],\n",
       "       [4.589306 ],\n",
       "       [4.039826 ],\n",
       "       [4.5561943],\n",
       "       [2.1563222],\n",
       "       [3.7417529],\n",
       "       [5.6996984],\n",
       "       [3.3149943],\n",
       "       [4.8737063],\n",
       "       [4.6281967],\n",
       "       [4.8704615],\n",
       "       [4.8666205],\n",
       "       [4.603655 ],\n",
       "       [4.9512696],\n",
       "       [4.221295 ],\n",
       "       [4.0061617],\n",
       "       [4.587038 ],\n",
       "       [5.710164 ],\n",
       "       [7.1594524],\n",
       "       [2.7411845],\n",
       "       [3.3858464],\n",
       "       [4.252991 ],\n",
       "       [5.3314176],\n",
       "       [4.2129626],\n",
       "       [2.7888694],\n",
       "       [3.9416728],\n",
       "       [3.6028123],\n",
       "       [3.3873386],\n",
       "       [4.9317083],\n",
       "       [3.1071515],\n",
       "       [4.583495 ],\n",
       "       [5.88976  ],\n",
       "       [4.5765963],\n",
       "       [3.4640605],\n",
       "       [5.992801 ],\n",
       "       [4.644556 ],\n",
       "       [4.495939 ],\n",
       "       [5.078309 ],\n",
       "       [5.4120946],\n",
       "       [2.3667474],\n",
       "       [4.5017033],\n",
       "       [6.7390394],\n",
       "       [4.1576138],\n",
       "       [3.5907323],\n",
       "       [4.840952 ],\n",
       "       [6.5820713],\n",
       "       [6.14057  ],\n",
       "       [3.0009606],\n",
       "       [4.38047  ],\n",
       "       [2.3310692],\n",
       "       [2.0575604],\n",
       "       [3.4651294],\n",
       "       [5.6324463],\n",
       "       [5.0318236],\n",
       "       [6.2494655],\n",
       "       [2.4476824],\n",
       "       [5.2763324],\n",
       "       [4.698555 ],\n",
       "       [4.1210976],\n",
       "       [4.391268 ],\n",
       "       [4.888301 ],\n",
       "       [3.5966327],\n",
       "       [7.892976 ],\n",
       "       [2.5859635],\n",
       "       [4.7495837],\n",
       "       [4.94959  ],\n",
       "       [5.929345 ],\n",
       "       [2.8015983],\n",
       "       [4.611905 ],\n",
       "       [1.8548589],\n",
       "       [5.6471443],\n",
       "       [4.036279 ],\n",
       "       [3.3008707],\n",
       "       [3.0294757],\n",
       "       [2.179753 ],\n",
       "       [4.2038717],\n",
       "       [7.179969 ],\n",
       "       [2.2626035],\n",
       "       [3.6896746],\n",
       "       [2.547474 ],\n",
       "       [2.1390111],\n",
       "       [2.2914417],\n",
       "       [4.394471 ],\n",
       "       [5.2037625],\n",
       "       [5.1909676],\n",
       "       [4.109013 ],\n",
       "       [4.414254 ],\n",
       "       [4.947474 ],\n",
       "       [5.543784 ],\n",
       "       [4.441985 ],\n",
       "       [2.7571132],\n",
       "       [3.438434 ],\n",
       "       [5.4918036],\n",
       "       [5.162897 ],\n",
       "       [5.93072  ],\n",
       "       [4.6371365],\n",
       "       [6.6736917],\n",
       "       [6.596231 ],\n",
       "       [2.3777418],\n",
       "       [5.5199013],\n",
       "       [3.888449 ],\n",
       "       [2.9587939],\n",
       "       [4.153099 ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object representative_dataset at 0x000001D52B0C7DC8>\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data =  x_train\n",
    "      yield [data.astype(np.float32)]\n",
    "\n",
    "print(representative_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_QSAR_model_keras_dir\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"saved_QSAR_model_keras_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_QSAR_model_keras_dir\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('QSARClassifyModel_new.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"QSARClassifyModel_new.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_details:\n",
      " [{'name': 'serving_default_input_2:0', 'index': 0, 'shape': array([1, 8]), 'shape_signature': array([-1,  8]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "output_details:\n",
      " [{'name': 'StatefulPartitionedCall:0', 'index': 8, 'shape': array([1, 1]), 'shape_signature': array([-1,  1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print('input_details:\\n', input_details)\n",
    "print('output_details:\\n', output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_np = x_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 8]\n",
      "[[6.2109194]]\n",
      "6.064\n"
     ]
    }
   ],
   "source": [
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "input_data = [x_test_np[0]]\n",
    "#print(input_data)\n",
    "input_data = np.array(input_data, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print(y_test_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert some hex values into an array for C programming\n",
    "import time, sys\n",
    "\n",
    "# Function to convert some hex values into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "    c_str = \"\"\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += \"#define \" + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    c_str += \"/*\\n Author: Mouli Sankaran \\n\"\n",
    "    c_str += \" CAUTION: This is an auto generated file.\\n DO NOT EDIT OR MAKE ANY CHANGES TO IT.\\n\"\n",
    "\n",
    "# Time stamping of this model data in the generated file\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    c_str += \" This model data was generated on \" + localtime+ '\\n\\n'\n",
    "    print(\"This model data was generated on:\", localtime)\n",
    "\n",
    "# Add information about the verisons of tools and packages used in generating this header file\n",
    "    c_str += \" Tools used:\\n Python:\" + str(sys.version) + \"\\n Numpy:\" \\\n",
    "            + str(np.version.version) + \"\\n TensorFlow:\" + str(sys.version) \\\n",
    "            + \"\\n Keras: \"+ str(tf.keras.__version__) + \"\\n\\n\"\n",
    "    print(\"Tools used: Python:\", sys.version, \"\\n Numpy:\", np.version.version, \\\n",
    "          \"\\n TensorFlow:\", sys.version, \"\\n Keras: \", tf.keras.__version__, \"\\n\\n\")\n",
    "\n",
    "# Training details of the model\n",
    "    c_str += ' Model details are:\\n'\n",
    "    c_str += ' NUM_OF_EPOCHS  = ' + str(NUM_OF_EPOCHS) + '\\n*/\\n'\n",
    "\n",
    "# Generate 'C' constants for the no. of nodes in each layer\n",
    "    c_str +=   'const int ' + 'DENSE1_SIZE' + ' = ' + str(DENSE1_SIZE) + ';\\n'\n",
    "\n",
    "    # Add array length at the top of the file\n",
    "    c_str += '\\nalignas(8) const unsigned int ' + var_name + '_len = '\\\n",
    "            + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data):\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formating so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "          hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "          hex_str += '\\n'\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n' + format(''.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model data was generated on: Sun Nov 10 22:48:39 2024\n",
      "Tools used: Python: 3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)] \n",
      " Numpy: 1.19.5 \n",
      " TensorFlow: 3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)] \n",
      " Keras:  2.7.0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"QSAR_model_esp32_new\" + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_model, \"QSAR_model_esp32_new\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(x_test_np[0])\n",
    "x_train_np = x_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x_test0_hex(data, name):\n",
    "#    print('\\n ', name, ':\\n {')\n",
    "    c_str = 'float ' + name + '[784] = { '\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "#            print(' ', data[i][j], 'f,', sep='', end='')\n",
    "            c_str += \"%s%f%s\" % (' ', data[i][j], 'f,')\n",
    "\n",
    "    c_str += '\\n};\\n'\n",
    "#    print('\\n};\\n')\n",
    "    return c_str\n",
    "\n",
    "\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(\"QSAR_x_test0_data_new\" + '.h', 'w') as file:\n",
    "    file.write(gen_x_test0_hex(x_test_np, 'x_test0'))\n",
    "\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(\"QSAR_x_train0_data_new\" + '.h', 'w') as file:\n",
    "    file.write(gen_x_test0_hex(x_train_np, 'x_train0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
