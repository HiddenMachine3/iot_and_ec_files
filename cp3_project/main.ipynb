{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>H-050</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>RDCHI</th>\n",
       "      <th>GATS1p</th>\n",
       "      <th>nN</th>\n",
       "      <th>C-040</th>\n",
       "      <th>quantitative response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.419</td>\n",
       "      <td>1.225</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.638</td>\n",
       "      <td>1.401</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.799</td>\n",
       "      <td>2.930</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.453</td>\n",
       "      <td>2.887</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.068</td>\n",
       "      <td>2.758</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TPSA(Tot)  SAacc  H-050  MLOGP  RDCHI  GATS1p  nN  C-040  \\\n",
       "0       0.00    0.0      0  2.419  1.225   0.667   0      0   \n",
       "1       0.00    0.0      0  2.638  1.401   0.632   0      0   \n",
       "2       9.23   11.0      0  5.799  2.930   0.486   0      0   \n",
       "3       9.23   11.0      0  5.453  2.887   0.495   0      0   \n",
       "4       9.23   11.0      0  4.068  2.758   0.695   0      0   \n",
       "\n",
       "   quantitative response  \n",
       "0                  3.740  \n",
       "1                  4.330  \n",
       "2                  7.019  \n",
       "3                  6.723  \n",
       "4                  5.979  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"TPSA(Tot)\", \"SAacc\", \"H-050\", \"MLOGP\", \"RDCHI\", \"GATS1p\", \"nN\", \"C-040\", \"quantitative response\"]\n",
    "df = pd.read_csv('qsar_aquatic_toxicity.csv', names=column_names, delimiter=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "x_train, y_train = train_df.drop('quantitative response', axis=1), train_df['quantitative response']\n",
    "x_test, y_test = test_df.drop('quantitative response', axis=1), test_df['quantitative response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPSA(Tot)</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>H-050</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>RDCHI</th>\n",
       "      <th>GATS1p</th>\n",
       "      <th>nN</th>\n",
       "      <th>C-040</th>\n",
       "      <th>quantitative response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>3.374</td>\n",
       "      <td>2.075</td>\n",
       "      <td>1.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>67.79</td>\n",
       "      <td>107.839</td>\n",
       "      <td>2</td>\n",
       "      <td>2.347</td>\n",
       "      <td>3.243</td>\n",
       "      <td>1.400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>45.34</td>\n",
       "      <td>34.106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.297</td>\n",
       "      <td>2.042</td>\n",
       "      <td>1.933</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>40.46</td>\n",
       "      <td>85.367</td>\n",
       "      <td>2</td>\n",
       "      <td>5.255</td>\n",
       "      <td>3.001</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>6.470</td>\n",
       "      <td>2.821</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TPSA(Tot)    SAacc  H-050  MLOGP  RDCHI  GATS1p  nN  C-040  \\\n",
       "438       0.00    0.000      0  3.374  2.075   1.204   0      0   \n",
       "359      67.79  107.839      2  2.347  3.243   1.400   1      1   \n",
       "447      45.34   34.106      0  1.297  2.042   1.933   0      0   \n",
       "37       40.46   85.367      2  5.255  3.001   0.485   0      0   \n",
       "248       0.00    0.000      0  6.470  2.821   0.469   0      0   \n",
       "\n",
       "     quantitative response  \n",
       "438                  3.792  \n",
       "359                  3.917  \n",
       "447                  2.829  \n",
       "37                   4.838  \n",
       "248                  8.440  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1152      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DENSE1_SIZE = 128\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Input(shape=(x_train.shape[1:])),\n",
    "  tf.keras.layers.Dense(DENSE1_SIZE, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.00876"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_test.to_numpy(), predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy', 'mse', 'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14/14 [==============================] - 1s 22ms/step - loss: 138.2345 - accuracy: 0.0000e+00 - mse: 138.2345 - mae: 7.5341 - val_loss: 19.9593 - val_accuracy: 0.0000e+00 - val_mse: 19.9593 - val_mae: 4.0622\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 58.7647 - accuracy: 0.0000e+00 - mse: 58.7647 - mae: 6.0424 - val_loss: 15.1716 - val_accuracy: 0.0000e+00 - val_mse: 15.1716 - val_mae: 3.4770\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 72.7228 - accuracy: 0.0000e+00 - mse: 72.7228 - mae: 5.4786 - val_loss: 9.5880 - val_accuracy: 0.0000e+00 - val_mse: 9.5880 - val_mae: 2.6137\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 53.6905 - accuracy: 0.0000e+00 - mse: 53.6905 - mae: 5.1570 - val_loss: 13.7884 - val_accuracy: 0.0000e+00 - val_mse: 13.7884 - val_mae: 3.3388\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 57.6379 - accuracy: 0.0000e+00 - mse: 57.6379 - mae: 4.8107 - val_loss: 7.5775 - val_accuracy: 0.0000e+00 - val_mse: 7.5775 - val_mae: 2.2290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12341cfd6c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_OF_EPOCHS = 5\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test), epochs=NUM_OF_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 7.5775 - accuracy: 0.0000e+00 - mse: 7.5775 - mae: 2.2290 - 31ms/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.577507972717285, 0.0, 7.577507972717285, 2.2290146350860596]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object representative_dataset at 0x0000012340AAF9C8>\n"
     ]
    }
   ],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "      data =  x_train\n",
    "      yield [data.astype(np.float32)]\n",
    "\n",
    "print(representative_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_QSAR_model_keras_dir\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"saved_QSAR_model_keras_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"saved_QSAR_model_keras_dir\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('QSARClassifyModel_new.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"QSARClassifyModel_new.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_details:\n",
      " [{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([1, 8]), 'shape_signature': array([-1,  8]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
      "output_details:\n",
      " [{'name': 'StatefulPartitionedCall:0', 'index': 8, 'shape': array([1, 1]), 'shape_signature': array([-1,  1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
     ]
    }
   ],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "print('input_details:\\n', input_details)\n",
    "print('output_details:\\n', output_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_np = x_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 8]\n",
      "[[6.6315546]]\n",
      "2.072\n"
     ]
    }
   ],
   "source": [
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "input_data = [x_test_np[0]]\n",
    "#print(input_data)\n",
    "input_data = np.array(input_data, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n",
    "print(y_test_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert some hex values into an array for C programming\n",
    "import time, sys\n",
    "\n",
    "# Function to convert some hex values into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "    c_str = \"\"\n",
    "\n",
    "    # Create header guard\n",
    "    c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "    c_str += \"#define \" + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "    c_str += \"/*\\n Author: Mouli Sankaran \\n\"\n",
    "    c_str += \" CAUTION: This is an auto generated file.\\n DO NOT EDIT OR MAKE ANY CHANGES TO IT.\\n\"\n",
    "\n",
    "# Time stamping of this model data in the generated file\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    c_str += \" This model data was generated on \" + localtime+ '\\n\\n'\n",
    "    print(\"This model data was generated on:\", localtime)\n",
    "\n",
    "# Add information about the verisons of tools and packages used in generating this header file\n",
    "    c_str += \" Tools used:\\n Python:\" + str(sys.version) + \"\\n Numpy:\" \\\n",
    "            + str(np.version.version) + \"\\n TensorFlow:\" + str(sys.version) \\\n",
    "            + \"\\n Keras: \"+ str(tf.keras.__version__) + \"\\n\\n\"\n",
    "    print(\"Tools used: Python:\", sys.version, \"\\n Numpy:\", np.version.version, \\\n",
    "          \"\\n TensorFlow:\", sys.version, \"\\n Keras: \", tf.keras.__version__, \"\\n\\n\")\n",
    "\n",
    "# Training details of the model\n",
    "    c_str += ' Model details are:\\n'\n",
    "    c_str += ' NUM_OF_EPOCHS  = ' + str(NUM_OF_EPOCHS) + '\\n*/\\n'\n",
    "\n",
    "# Generate 'C' constants for the no. of nodes in each layer\n",
    "    c_str +=   'const int ' + 'DENSE1_SIZE' + ' = ' + str(DENSE1_SIZE) + ';\\n'\n",
    "\n",
    "    # Add array length at the top of the file\n",
    "    c_str += '\\nalignas(8) const unsigned int ' + var_name + '_len = '\\\n",
    "            + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "    # Declare C variable\n",
    "    c_str += 'const unsigned char ' + var_name + '[] = {'\n",
    "    hex_array = []\n",
    "    for i, val in enumerate(hex_data):\n",
    "        # Construct string from hex\n",
    "        hex_str = format(val, '#04x')\n",
    "\n",
    "        # Add formating so each line stays within 80 characters\n",
    "        if (i + 1) < len(hex_data):\n",
    "          hex_str += ','\n",
    "        if (i + 1) % 12 == 0:\n",
    "          hex_str += '\\n'\n",
    "        hex_array.append(hex_str)\n",
    "\n",
    "    # Add closing brace\n",
    "    c_str += '\\n' + format(''.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "    # Close out header guard\n",
    "    c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "    return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model data was generated on: Wed Nov  6 00:20:26 2024\n",
      "Tools used: Python: 3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)] \n",
      " Numpy: 1.19.5 \n",
      " TensorFlow: 3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)] \n",
      " Keras:  2.7.0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"QSAR_model_esp32_new\" + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_model, \"QSAR_model_esp32_new\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(x_test_np[0])\n",
    "x_train_np = x_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_x_test0_hex(data, name):\n",
    "#    print('\\n ', name, ':\\n {')\n",
    "    c_str = 'float ' + name + '[784] = { '\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "#            print(' ', data[i][j], 'f,', sep='', end='')\n",
    "            c_str += \"%s%f%s\" % (' ', data[i][j], 'f,')\n",
    "\n",
    "    c_str += '\\n};\\n'\n",
    "#    print('\\n};\\n')\n",
    "    return c_str\n",
    "\n",
    "\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(\"QSAR_x_test0_data_new\" + '.h', 'w') as file:\n",
    "    file.write(gen_x_test0_hex(x_test_np, 'x_test0'))\n",
    "\n",
    "# Write TFLite model to a C source (or header) file\n",
    "with open(\"QSAR_x_train0_data_new\" + '.h', 'w') as file:\n",
    "    file.write(gen_x_test0_hex(x_train_np, 'x_train0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
